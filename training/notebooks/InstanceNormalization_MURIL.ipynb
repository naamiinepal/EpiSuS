{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDGSAhy4mcJ4"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyLMqs67z2MJ"
      },
      "source": [
        "We will use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models). `tensorflow-text` is a dependency of the preprocessing for BERT inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "skUvL_xZmPgC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import tensorflow_text as text  # For preprocessor\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDQSWmz1KMr7"
      },
      "source": [
        "# Make notebook reproducible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u5fy6ZL98u5_"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# physical_devices= tf.config.list_physical_devices('GPU')\n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOtOVNUmyR8"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qmGSn34ULxY"
      },
      "source": [
        "## Loading the dataset in pandas and doing test, train split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F9d8yE0maA0n"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"../datasets/nepali_tweets_dataset_labelled_tweets_feb_23\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "FOLD = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os.path\n",
        "from glob import glob\n",
        "\n",
        "val_filepath = os.path.join(BASE_DIR, f\"fold_{FOLD}.csv\")\n",
        "\n",
        "train_files = glob(os.path.join(BASE_DIR, \"*.csv\"))\n",
        "train_files.remove(val_filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_df = pd.read_csv(val_filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>covid_stats</th>\n",
              "      <th>vaccination</th>\n",
              "      <th>covid_politics</th>\n",
              "      <th>humour</th>\n",
              "      <th>lockdown</th>\n",
              "      <th>civic_views</th>\n",
              "      <th>life_during_pandemic</th>\n",
              "      <th>covid_waves_and_variants</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>केही दिन यता वीर हस्पिटलमा कोरोना जॅाच गराउन आ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>भूटानले पठायो नेपालमा तीन लाख अष्ट्राजेनिकाको ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>चीनका चार कम्पनीले कोभिड–१९ को खोप बिक्री गर्न...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>हिमालपारिको दुःखः ट्रयाक्टरमा खोप ढुवानी</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>यो ट्वीट खोप लगाउनेहरुले आरटी,लगाउन तयार हुनेल...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  covid_stats  \\\n",
              "0  केही दिन यता वीर हस्पिटलमा कोरोना जॅाच गराउन आ...            1   \n",
              "1  भूटानले पठायो नेपालमा तीन लाख अष्ट्राजेनिकाको ...            0   \n",
              "2  चीनका चार कम्पनीले कोभिड–१९ को खोप बिक्री गर्न...            0   \n",
              "3           हिमालपारिको दुःखः ट्रयाक्टरमा खोप ढुवानी            0   \n",
              "4  यो ट्वीट खोप लगाउनेहरुले आरटी,लगाउन तयार हुनेल...            0   \n",
              "\n",
              "   vaccination  covid_politics  humour  lockdown  civic_views  \\\n",
              "0            0               0       0         0            1   \n",
              "1            1               1       0         0            0   \n",
              "2            1               1       0         0            0   \n",
              "3            1               0       0         0            0   \n",
              "4            1               0       1         0            0   \n",
              "\n",
              "   life_during_pandemic  covid_waves_and_variants  \n",
              "0                     0                         0  \n",
              "1                     0                         0  \n",
              "2                     0                         0  \n",
              "3                     1                         0  \n",
              "4                     0                         0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.concat(map(pd.read_csv, train_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSrwxrykRNA4",
        "outputId": "339e9694-b1e7-407d-b90f-ca125853f17e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>covid_stats</th>\n",
              "      <th>vaccination</th>\n",
              "      <th>covid_politics</th>\n",
              "      <th>humour</th>\n",
              "      <th>lockdown</th>\n",
              "      <th>civic_views</th>\n",
              "      <th>life_during_pandemic</th>\n",
              "      <th>covid_waves_and_variants</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>देशभर थपिए २,६२२ कोरोना संक्रमित, २३ जनाको मृत्यु</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>संसदको शिक्षा तथा स्वास्थ समितिले कक्षा १२ को ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ले आफ्ना हवाईयात्रुमाझ हालै गरेको सर्वेक्षणले ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>केही आदत के बानि पुनर्जन्म लिएर आउदा पनि बदलिद...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>सरकारले मन्त्रीपरिषदलाई पूर्णता दिन नसक्नु र ढ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  covid_stats  \\\n",
              "0  देशभर थपिए २,६२२ कोरोना संक्रमित, २३ जनाको मृत्यु            1   \n",
              "1  संसदको शिक्षा तथा स्वास्थ समितिले कक्षा १२ को ...            0   \n",
              "2  ले आफ्ना हवाईयात्रुमाझ हालै गरेको सर्वेक्षणले ...            1   \n",
              "3  केही आदत के बानि पुनर्जन्म लिएर आउदा पनि बदलिद...            0   \n",
              "4  सरकारले मन्त्रीपरिषदलाई पूर्णता दिन नसक्नु र ढ...            0   \n",
              "\n",
              "   vaccination  covid_politics  humour  lockdown  civic_views  \\\n",
              "0            0               0       0         0            0   \n",
              "1            1               1       0         0            0   \n",
              "2            1               0       0         0            1   \n",
              "3            1               0       1         0            0   \n",
              "4            1               1       0         0            1   \n",
              "\n",
              "   life_during_pandemic  covid_waves_and_variants  \n",
              "0                     0                         0  \n",
              "1                     0                         0  \n",
              "2                     0                         0  \n",
              "3                     0                         0  \n",
              "4                     0                         0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9793 entries, 0 to 2447\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   text                      9793 non-null   object\n",
            " 1   covid_stats               9793 non-null   int64 \n",
            " 2   vaccination               9793 non-null   int64 \n",
            " 3   covid_politics            9793 non-null   int64 \n",
            " 4   humour                    9793 non-null   int64 \n",
            " 5   lockdown                  9793 non-null   int64 \n",
            " 6   civic_views               9793 non-null   int64 \n",
            " 7   life_during_pandemic      9793 non-null   int64 \n",
            " 8   covid_waves_and_variants  9793 non-null   int64 \n",
            "dtypes: int64(8), object(1)\n",
            "memory usage: 765.1+ KB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KW-Nzilma9dj"
      },
      "outputs": [],
      "source": [
        "text_train = train_df[\"text\"]\n",
        "text_val = val_df[\"text\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_train = train_df.iloc[:, 1:]\n",
        "label_val = val_df.iloc[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "covid_stats                 0.164709\n",
              "vaccination                 0.335035\n",
              "covid_politics              0.210150\n",
              "humour                      0.134586\n",
              "lockdown                    0.131727\n",
              "civic_views                 0.226182\n",
              "life_during_pandemic        0.144797\n",
              "covid_waves_and_variants    0.141019\n",
              "dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "expected_prob = label_train.mean()\n",
        "expected_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qIqUvPdOTJh",
        "outputId": "de41dcdf-4183-4e68-a3d5-36365691a792"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08199734504237721"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def others_prob(label_ds: pd.DataFrame):\n",
        "    horz_sum = label_ds.sum(axis=1)\n",
        "    return (horz_sum == 0).sum() / len(horz_sum)\n",
        "\n",
        "\n",
        "others_prob(label_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCm5N23hbpu4",
        "outputId": "59ab172c-02fa-4343-b27a-3f1668529c84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_CLASSES = len(label_train.columns)\n",
        "NUM_CLASSES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQpCpxeNSrdD",
        "outputId": "b6b4fdf6-d8db-4740-eb80-179c43bd5cc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "covid_stats                 1613\n",
              "vaccination                 3281\n",
              "covid_politics              2058\n",
              "humour                      1318\n",
              "lockdown                    1290\n",
              "civic_views                 2215\n",
              "life_during_pandemic        1418\n",
              "covid_waves_and_variants    1381\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_train.sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joDsSCqlSudp",
        "outputId": "ff6d41af-33e8-4785-ef04-68c95f0563ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "covid_stats                 413\n",
              "vaccination                 803\n",
              "covid_politics              500\n",
              "humour                      315\n",
              "lockdown                    314\n",
              "civic_views                 581\n",
              "life_during_pandemic        374\n",
              "covid_waves_and_variants    342\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_val.sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLzmRPki99oX"
      },
      "source": [
        "### Create a bias initializer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hKGJZBMs9YBT"
      },
      "outputs": [],
      "source": [
        "pos = label_train.sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agxskkrQ-NQ6",
        "outputId": "f2dcdf8e-72eb-4520-ba2d-359562c281ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "covid_stats                 8180\n",
              "vaccination                 6512\n",
              "covid_politics              7735\n",
              "humour                      8475\n",
              "lockdown                    8503\n",
              "civic_views                 7578\n",
              "life_during_pandemic        8375\n",
              "covid_waves_and_variants    8412\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg = label_train.count() - pos\n",
        "neg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo2cv2N46KSF",
        "outputId": "435e4302-1319-473f-f20d-7fded8fdb3ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.62359635, -0.68549837, -1.32402085, -1.86100522, -1.88577682,\n",
              "       -1.22999691, -1.77600365, -1.80685138])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bias_initializer = (np.log(pos) - np.log(neg)).to_numpy()\n",
        "bias_initializer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9793"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytFXE9YGUSta"
      },
      "source": [
        "## Create `tf.data.Dataset` from pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-11 11:16:37.902891: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-11 11:16:38.745417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11397 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:b4:00.0, compute capability: 6.1\n",
            "2022-08-11 11:16:38.745977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10410 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:b3:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of GPUs: 2\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of GPUs:\", strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-Nn-Qcnmc-3W"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(train_df)\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 32  # Decrease if OOM\n",
        "\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "C72XJ28yU3yC"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((text_train, label_train))\n",
        "    .cache()\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(GLOBAL_BATCH_SIZE)\n",
        "    .prefetch(-1)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fuEPzwiNVMw_"
      },
      "outputs": [],
      "source": [
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((text_val, label_val))\n",
        "    .batch(GLOBAL_BATCH_SIZE)\n",
        "    .cache()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2TrKIxm3JX"
      },
      "source": [
        "# Loading models from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NFjUTDBmLlRr"
      },
      "outputs": [],
      "source": [
        "model = \"muril\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RcshvGB_neYn"
      },
      "outputs": [],
      "source": [
        "if model == \"muril\":\n",
        "    tfhub_handle_encoder = \"https://tfhub.dev/google/MuRIL/1\"\n",
        "    tfhub_handle_preprocess = \"https://tfhub.dev/google/MuRIL_preprocess/1\"\n",
        "else:\n",
        "    tfhub_handle_encoder = (\n",
        "        \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\"\n",
        "    )\n",
        "    tfhub_handle_preprocess = (\n",
        "        \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNHG7C1r50Hn"
      },
      "source": [
        "The used model is [MURIL: Multilingual Representations for Indian Languages](https://arxiv.org/abs/2103.10730). A BERT model pre-trained on 17 Indian languages, and their transliterated counterparts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxlHQ2IpgFk"
      },
      "source": [
        "# Define your model\n",
        "\n",
        "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EmqzmqCsSKdq"
      },
      "outputs": [],
      "source": [
        "DROPOUT_RATE = 0.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tj7RItPIpfZa"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name=\"preprocessing\")\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name=\"BERT_encoder\")\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs[\"pooled_output\"]\n",
        "    net = tf.keras.layers.Dropout(DROPOUT_RATE)(net)\n",
        "    net = tfa.layers.InstanceNormalization()(net)\n",
        "    net = tf.keras.layers.Dense(\n",
        "        NUM_CLASSES,\n",
        "        bias_initializer=tf.keras.initializers.Constant(bias_initializer),\n",
        "        name=\"classifier\",\n",
        "    )(net)\n",
        "    return tf.keras.Model(text_input, net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eqDG1S-c_HOo"
      },
      "outputs": [],
      "source": [
        "# classifier_model = build_classifier_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeD5qa_r_n26",
        "outputId": "b86f4019-736d-459d-a57d-e1bc1eeec384"
      },
      "outputs": [],
      "source": [
        "# pred = classifier_model(tf.constant(text_test))\n",
        "# print(tf.sigmoid(pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XuXg4jam_TCs",
        "outputId": "2f54d2c4-72ed-431f-f32c-76e9375a6e73"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(classifier_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLjd3bNOrJW6"
      },
      "source": [
        "# Model training\n",
        "\n",
        "You now have all the pieces to train a model, including the preprocessing module, BERT encoder, data, and classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOiGOkN9zOeC"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "### Needs a change\n",
        "\n",
        "Since this is a multilabel classification problem and the model outputs a probability (a single-unit layer), you'll use [`losses.BinaryCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "m0eTBPTtsD8t"
      },
      "outputs": [],
      "source": [
        "def get_loss_metrics():\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    metrics = [\n",
        "        tf.metrics.BinaryAccuracy(),\n",
        "        tfa.metrics.F1Score(num_classes=NUM_CLASSES, average=\"weighted\", threshold=0.5),\n",
        "        tf.keras.metrics.AUC(\n",
        "            len(label_val),\n",
        "            curve=\"PR\",\n",
        "            multi_label=True,\n",
        "            num_labels=NUM_CLASSES,\n",
        "            from_logits=True,\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    return loss, metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZQY-NqAzGkx"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "For fine-tuning, let's use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "For the learning rate (`init_lr`), you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BOEVFIDBzi0A"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 9\n",
        "INIT_LR = 5e-5  # best of 5e-5, 3e-5, 2e-5\n",
        "\n",
        "\n",
        "def get_optimizer():\n",
        "    steps_per_epoch = int(tf.data.experimental.cardinality(train_ds))\n",
        "    num_train_steps = steps_per_epoch * EPOCHS\n",
        "    num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "    optimizer = optimization.create_optimizer(\n",
        "        init_lr=INIT_LR,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        optimizer_type=\"adamw\",\n",
        "    )\n",
        "    return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhD2AK21D4wO"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GE1YbN_Rcfbp"
      },
      "outputs": [],
      "source": [
        "project_name = \"final_submission\"\n",
        "MODEL_BASE_DIR = f\"../{project_name}/{model}_instancenorm_d{DROPOUT_RATE}_fold{FOLD}/\"\n",
        "LOG_DIR = MODEL_BASE_DIR + \"runs\"\n",
        "CHECKPOINT_DIR = MODEL_BASE_DIR + \"checkpoints/{epoch:02d}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rrgzs9NTWGfH",
        "outputId": "70b5bee1-d686-4e27-eac5-3057e72283f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrabinadk1\u001b[0m (\u001b[33mquarks\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/SSD0/rabin/EpiSuS/training/notebooks/wandb/run-20220811_111655-4ecajvs8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/quarks/final_submission/runs/4ecajvs8\" target=\"_blank\">efficient-night-12</a></strong> to <a href=\"https://wandb.ai/quarks/final_submission\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.init(project=project_name, entity=\"quarks\")\n",
        "wandb.config = {\n",
        "    \"init_lr\": INIT_LR,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": GLOBAL_BATCH_SIZE,\n",
        "    \"dropout_rate\": DROPOUT_RATE,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WU_-ogTwEATd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        }
      ],
      "source": [
        "monitor = \"val_auc\"\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=5, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=CHECKPOINT_DIR,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "    WandbCallback(monitor=monitor, save_weights_only=True),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9MWjsy-2BGD"
      },
      "source": [
        "## Loading the BERT model and training\n",
        "\n",
        "Using the classifier_model you created earlier, you can compile the model with the loss, metric and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-3oF5nVZ2E4F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-11 11:17:04.319351: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    classifier_model = build_classifier_model()\n",
        "    loss, metrics = get_loss_metrics()\n",
        "    optimizer = get_optimizer()\n",
        "    classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(classifier_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmyvX_xqFjp5",
        "outputId": "6fc0b6d5-cf78-4e30-ff4a-2661fe2a95cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  237556225   ['preprocessing[0][0]',          \n",
            "                                None, 768),                       'preprocessing[0][1]',          \n",
            "                                 'default': (None,                'preprocessing[0][2]']          \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, None, 768),                                               \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                ]}                                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['BERT_encoder[0][13]']          \n",
            "                                                                                                  \n",
            " instance_normalization (Instan  (None, 768)         1536        ['dropout[0][0]']                \n",
            " ceNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 8)            6152        ['instance_normalization[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 237,563,913\n",
            "Trainable params: 237,563,912\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxKWRNcPeOTY",
        "outputId": "b53153b1-a1c3-4e26-ee0e-1035cede9752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Aug 11 11:17:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:B3:00.0 Off |                  N/A |\n",
            "| 49%   35C    P2    65W / 250W |  10681MiB / 11264MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA TITAN Xp     Off  | 00000000:B4:00.0 Off |                  N/A |\n",
            "| 23%   42C    P2    67W / 250W |  11697MiB / 12288MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1273      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    0   N/A  N/A     71220      C   ...training/.venv/bin/python    10671MiB |\n",
            "|    1   N/A  N/A      1273      G   /usr/lib/xorg/Xorg                 18MiB |\n",
            "|    1   N/A  N/A      1455      G   /usr/bin/gnome-shell                5MiB |\n",
            "|    1   N/A  N/A     71220      C   ...training/.venv/bin/python    11667MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkz9tGho2NkW",
        "outputId": "17b87ba3-e2f9-403f-fe7c-ff7800b1efef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with https://tfhub.dev/google/MuRIL/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-11 11:17:15.636387: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_STRING\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 9793\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:0\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_STRING\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_INT64\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2022-08-11 11:17:15.800662: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
            "2022-08-11 11:17:15.800763: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
            "2022-08-11 11:17:15.802438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11397 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:b4:00.0, compute capability: 6.1\n",
            "2022-08-11 11:17:15.802586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10410 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:b3:00.0, compute capability: 6.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "154/154 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1833"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-11 11:19:36.234164: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_STRING\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 2448\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:5\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_STRING\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_INT64\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: saving model to ../final_submission/muril_instancenorm_d0.4_fold1/checkpoints/01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-11 11:19:48.923959: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "2022-08-11 11:19:49.460944: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "2022-08-11 11:19:50.003597: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "2022-08-11 11:19:52.853850: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 360). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /mnt/SSD0/rabin/EpiSuS/training/notebooks/wandb/run-20220811_111655-4ecajvs8/files/model-best/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /mnt/SSD0/rabin/EpiSuS/training/notebooks/wandb/run-20220811_111655-4ecajvs8/files/model-best/assets\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/mnt/SSD0/rabin/EpiSuS/training/notebooks/wandb/run-20220811_111655-4ecajvs8/files/model-best)... Done. 7.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "154/154 [==============================] - 179s 986ms/step - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1833 - val_loss: 0.4676 - val_binary_accuracy: 0.8140 - val_f1_score: 0.0000e+00 - val_auc: 0.1860\n",
            "Epoch 2/9\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1813\n",
            "Epoch 2: saving model to ../final_submission/muril_instancenorm_d0.4_fold1/checkpoints/02\n",
            "154/154 [==============================] - 127s 824ms/step - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1813 - val_loss: 0.4676 - val_binary_accuracy: 0.8140 - val_f1_score: 0.0000e+00 - val_auc: 0.1860\n",
            "Epoch 3/9\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1812\n",
            "Epoch 3: saving model to ../final_submission/muril_instancenorm_d0.4_fold1/checkpoints/03\n",
            "154/154 [==============================] - 128s 831ms/step - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1812 - val_loss: 0.4676 - val_binary_accuracy: 0.8140 - val_f1_score: 0.0000e+00 - val_auc: 0.1860\n",
            "Epoch 4/9\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1826\n",
            "Epoch 4: saving model to ../final_submission/muril_instancenorm_d0.4_fold1/checkpoints/04\n",
            "154/154 [==============================] - 128s 830ms/step - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1826 - val_loss: 0.4676 - val_binary_accuracy: 0.8140 - val_f1_score: 0.0000e+00 - val_auc: 0.1860\n",
            "Epoch 5/9\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1813\n",
            "Epoch 5: saving model to ../final_submission/muril_instancenorm_d0.4_fold1/checkpoints/05\n",
            "154/154 [==============================] - 129s 838ms/step - loss: 0.4674 - binary_accuracy: 0.8140 - f1_score: 0.0000e+00 - auc: 0.1813 - val_loss: 0.4676 - val_binary_accuracy: 0.8140 - val_f1_score: 0.0000e+00 - val_auc: 0.1860\n",
            "Epoch 6/9\n",
            " 59/154 [==========>...................] - ETA: 1:11 - loss: 0.4655 - binary_accuracy: 0.8152 - f1_score: 0.0000e+00 - auc: 0.1828"
          ]
        }
      ],
      "source": [
        "print(f\"Training model with {tfhub_handle_encoder}\")\n",
        "history = classifier_model.fit(\n",
        "    x=train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omu5xKcp2RcH"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Let's see how the model performs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDW2niW52WS0",
        "outputId": "094ac70d-1294-4526-b963-2af08c3dacee"
      },
      "outputs": [],
      "source": [
        "# loss, accuracy, f1_score, auc = classifier_model.evaluate(val_ds)\n",
        "\n",
        "# print(f\"Loss: {loss}\")\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Weighted F1 Score at 0.5 Threshold: {f1_score}\")\n",
        "# print(f\"AUC: {auc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJN83f0z2aUH"
      },
      "source": [
        "## Plot the accuracy and loss over time\n",
        "\n",
        "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "KIZRsdNC2WYX",
        "outputId": "e74eee4a-9bf0-4593-a355-aa8ec2aee41f"
      },
      "outputs": [],
      "source": [
        "# history_dict = history.history\n",
        "# print(history_dict.keys())\n",
        "\n",
        "# loss = history_dict[\"loss\"]\n",
        "# val_loss = history_dict[\"val_loss\"]\n",
        "\n",
        "# acc = history_dict[\"binary_accuracy\"]\n",
        "# val_acc = history_dict[\"val_binary_accuracy\"]\n",
        "\n",
        "# f1_score = history_dict[\"f1_score\"]\n",
        "# val_f1_score = history_dict[\"val_f1_score\"]\n",
        "\n",
        "# auc = history_dict[\"auc\"]\n",
        "# val_auc = history_dict[\"val_auc\"]\n",
        "\n",
        "# epochs = range(1, len(acc) + 1)\n",
        "# fig = plt.figure(figsize=(10, 10))\n",
        "# fig.tight_layout()\n",
        "\n",
        "# plt.subplot(2, 2, 1)\n",
        "# # r is for \"solid red line\"\n",
        "# plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
        "# # b is for \"solid blue line\"\n",
        "# plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "# plt.title(\"Training and validation loss\")\n",
        "# # plt.xlabel('Epochs')\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(2, 2, 2)\n",
        "# plt.plot(epochs, acc, \"r\", label=\"Training acc\")\n",
        "# plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "# plt.title(\"Training and validation accuracy\")\n",
        "# # plt.xlabel('Epochs')\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(2, 2, 3)\n",
        "# plt.plot(epochs, f1_score, \"r\", label=\"Training f1_score\")\n",
        "# plt.plot(epochs, val_f1_score, \"b\", label=\"Validation f1_score\")\n",
        "# plt.title(\"Training and validation f1_score\")\n",
        "# # plt.xlabel('Epochs')\n",
        "# plt.ylabel(\"f1_score\")\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(2, 2, 4)\n",
        "# plt.plot(epochs, auc, \"r\", label=\"Training auc\")\n",
        "# plt.plot(epochs, val_auc, \"b\", label=\"Validation auc\")\n",
        "# plt.title(\"Training and validation AUC\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"AUC\")\n",
        "# plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2vSCNI2sbZ"
      },
      "source": [
        "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Normalization MURIL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "3db1740dc4c63d05e0183029f245d99e342296d1ed403c3ef0b4079859e0c361"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
