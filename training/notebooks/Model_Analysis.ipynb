{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDGSAhy4mcJ4"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyLMqs67z2MJ"
      },
      "source": [
        "We will use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models). `tensorflow-text` is a dependency of the preprocessing for BERT inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "skUvL_xZmPgC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import tensorflow_text as text  # For preprocessor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDQSWmz1KMr7"
      },
      "source": [
        "# Make notebook reproducible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u5fy6ZL98u5_"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# physical_devices= tf.config.list_physical_devices('GPU')\n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOtOVNUmyR8"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qmGSn34ULxY"
      },
      "source": [
        "## Loading the dataset in pandas and doing test, train split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F9d8yE0maA0n"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"../datasets/nepali_tweets_dataset_labelled_tweets_feb_23\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "FOLD = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os.path\n",
        "\n",
        "val_filepath = os.path.join(BASE_DIR, f\"fold_{FOLD}.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_df = pd.read_csv(val_filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>covid_stats</th>\n",
              "      <th>vaccination</th>\n",
              "      <th>covid_politics</th>\n",
              "      <th>humour</th>\n",
              "      <th>lockdown</th>\n",
              "      <th>civic_views</th>\n",
              "      <th>life_during_pandemic</th>\n",
              "      <th>covid_waves_and_variants</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>देशभर थपिए २,६२२ कोरोना संक्रमित, २३ जनाको मृत्यु</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>संसदको शिक्षा तथा स्वास्थ समितिले कक्षा १२ को ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ले आफ्ना हवाईयात्रुमाझ हालै गरेको सर्वेक्षणले ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>केही आदत के बानि पुनर्जन्म लिएर आउदा पनि बदलिद...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>सरकारले मन्त्रीपरिषदलाई पूर्णता दिन नसक्नु र ढ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  covid_stats  \\\n",
              "0  देशभर थपिए २,६२२ कोरोना संक्रमित, २३ जनाको मृत्यु            1   \n",
              "1  संसदको शिक्षा तथा स्वास्थ समितिले कक्षा १२ को ...            0   \n",
              "2  ले आफ्ना हवाईयात्रुमाझ हालै गरेको सर्वेक्षणले ...            1   \n",
              "3  केही आदत के बानि पुनर्जन्म लिएर आउदा पनि बदलिद...            0   \n",
              "4  सरकारले मन्त्रीपरिषदलाई पूर्णता दिन नसक्नु र ढ...            0   \n",
              "\n",
              "   vaccination  covid_politics  humour  lockdown  civic_views  \\\n",
              "0            0               0       0         0            0   \n",
              "1            1               1       0         0            0   \n",
              "2            1               0       0         0            1   \n",
              "3            1               0       1         0            0   \n",
              "4            1               1       0         0            1   \n",
              "\n",
              "   life_during_pandemic  covid_waves_and_variants  \n",
              "0                     0                         0  \n",
              "1                     0                         0  \n",
              "2                     0                         0  \n",
              "3                     0                         0  \n",
              "4                     0                         0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_val = val_df[\"text\"]\n",
        "label_val = val_df.iloc[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCm5N23hbpu4",
        "outputId": "59ab172c-02fa-4343-b27a-3f1668529c84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_CLASSES = len(label_val.columns)\n",
        "NUM_CLASSES\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytFXE9YGUSta"
      },
      "source": [
        "## Create `tf.data.Dataset` from pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-16 18:04:31.632478: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-16 18:04:32.487097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11386 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:b4:00.0, compute capability: 6.1\n",
            "2022-08-16 18:04:32.487663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10410 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:b3:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of GPUs: 2\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of GPUs:\", strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-Nn-Qcnmc-3W"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE_PER_REPLICA = 32  # Decrease if OOM\n",
        "\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fuEPzwiNVMw_"
      },
      "outputs": [],
      "source": [
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((text_val, label_val))\n",
        "    .batch(GLOBAL_BATCH_SIZE)\n",
        "    .cache()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2TrKIxm3JX"
      },
      "source": [
        "# Loading models from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NFjUTDBmLlRr"
      },
      "outputs": [],
      "source": [
        "model = \"muril\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RcshvGB_neYn"
      },
      "outputs": [],
      "source": [
        "if model == \"muril\":\n",
        "    tfhub_handle_encoder = \"https://tfhub.dev/google/MuRIL/1\"\n",
        "    tfhub_handle_preprocess = \"https://tfhub.dev/google/MuRIL_preprocess/1\"\n",
        "else:\n",
        "    tfhub_handle_encoder = (\n",
        "        \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\"\n",
        "    )\n",
        "    tfhub_handle_preprocess = (\n",
        "        \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNHG7C1r50Hn"
      },
      "source": [
        "The used model is [MURIL: Multilingual Representations for Indian Languages](https://arxiv.org/abs/2103.10730). A BERT model pre-trained on 17 Indian languages, and their transliterated counterparts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxlHQ2IpgFk"
      },
      "source": [
        "# Define your model\n",
        "\n",
        "You will create a very simple fine-tuned model, with the preprocessing model, the selected BERT model, one Dense and a Dropout layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EmqzmqCsSKdq"
      },
      "outputs": [],
      "source": [
        "DROPOUT_RATE = 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tj7RItPIpfZa"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name=\"preprocessing\")\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name=\"BERT_encoder\")\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs[\"pooled_output\"]\n",
        "    net = tf.keras.layers.Dropout(DROPOUT_RATE)(net)\n",
        "    net = tf.keras.layers.BatchNormalization()(net)\n",
        "    net = tf.keras.layers.Dense(\n",
        "        NUM_CLASSES,\n",
        "        name=\"classifier\",\n",
        "    )(net)\n",
        "    return tf.keras.Model(text_input, net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-16 18:04:42.468301: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    classifier_model = build_classifier_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "BEST_EPOCHs = (3, 2, 3, 4, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-16 18:04:45.881240: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 606059520 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbe64568be0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_epoch = BEST_EPOCHs[FOLD - 1]\n",
        "\n",
        "checkpoint_dir = f\"../final_submission/muril_batchnorm_d{DROPOUT_RATE}_fold{FOLD}/checkpoints/{model_epoch:02d}\"\n",
        "classifier_model.load_weights(checkpoint_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9MWjsy-2BGD"
      },
      "source": [
        "## Loading the BERT model and training\n",
        "\n",
        "Using the classifier_model you created earlier, you can compile the model with the loss, metric and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkz9tGho2NkW",
        "outputId": "17b87ba3-e2f9-403f-fe7c-ff7800b1efef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-16 18:04:48.619025: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_STRING\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 2449\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\024TensorSliceDataset:0\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_STRING\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_INT64\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39/39 [==============================] - 12s 229ms/step\n"
          ]
        }
      ],
      "source": [
        "model_label_predict = classifier_model.predict(val_ds, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.4631066 , -2.1439724 , -2.1441016 , ..., -2.1448798 ,\n",
              "        -2.224648  , -2.264816  ],\n",
              "       [-2.6337361 ,  1.9093306 , -0.61603755, ..., -1.9338713 ,\n",
              "        -2.0850768 , -2.459852  ],\n",
              "       [-1.9571874 ,  1.8253846 , -2.0407062 , ..., -1.5352501 ,\n",
              "        -1.7386205 , -2.1552815 ],\n",
              "       ...,\n",
              "       [-1.7718469 , -1.902194  , -2.4454436 , ..., -1.9008374 ,\n",
              "        -0.4464903 , -1.405213  ],\n",
              "       [ 1.8137903 , -2.1037557 , -2.0843458 , ..., -2.1232135 ,\n",
              "        -2.2711468 , -2.3213222 ],\n",
              "       [-2.4020834 , -1.9544864 , -2.4577768 , ..., -0.87320286,\n",
              "        -1.7972351 , -2.1282306 ]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_label_predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "covid_stats: Max F1 Score 0.9095354523227385 at Threshold: -1.574108600616455 with AUC: 0.9628050091294714\n",
            "vaccination: Max F1 Score 0.9721728833629367 at Threshold: -0.24700897932052612 with AUC: 0.9855759431916088\n",
            "covid_politics: Max F1 Score 0.7309458218549127 at Threshold: -1.5019621849060059 with AUC: 0.7836967894199913\n",
            "humour: Max F1 Score 0.760932944606414 at Threshold: -1.1269872188568115 with AUC: 0.7878564526863515\n",
            "lockdown: Max F1 Score 0.9722675367047308 at Threshold: -0.5269203186035156 with AUC: 0.9943871438124847\n",
            "civic_views: Max F1 Score 0.7406749555950266 at Threshold: -0.8582739233970642 with AUC: 0.7707474013722544\n",
            "life_during_pandemic: Max F1 Score 0.6024999999999999 at Threshold: -1.548545241355896 with AUC: 0.6107519681798247\n",
            "covid_waves_and_variants: Max F1 Score 0.8458274398868458 at Threshold: -1.4590978622436523 with AUC: 0.9140972019627063\n"
          ]
        }
      ],
      "source": [
        "# precision recall curve, all labels in a single plot\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "\n",
        "threshold_array = np.zeros_like(label_val.columns, dtype=np.float32)\n",
        "f1_score_array = np.zeros_like(label_val.columns, dtype=np.float32)\n",
        "auc_array = np.zeros_like(label_val.columns, dtype=np.float32)\n",
        "\n",
        "for i, label in enumerate(label_val.columns):\n",
        "    precision, recall, thresholds = precision_recall_curve(\n",
        "        label_val.iloc[:, i], model_label_predict[:, i]\n",
        "    )\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "    f1_score = 2 * precision * recall / (precision + recall + 1e-16)\n",
        "\n",
        "    thresh_arg = f1_score.argmax()\n",
        "\n",
        "    max_f1_score = f1_score[thresh_arg]\n",
        "    max_thresh = thresholds[thresh_arg]\n",
        "\n",
        "    auc_pr = skm.auc(recall, precision)\n",
        "\n",
        "    threshold_array[i] = max_thresh\n",
        "    f1_score_array[i] = max_f1_score\n",
        "    auc_array[i] = auc_pr\n",
        "\n",
        "    print(\n",
        "        f\"{label}: Max F1 Score {max_f1_score} at Threshold: {max_thresh} with AUC: {auc_pr}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame(\n",
        "    {\n",
        "        \"f1_score\": f1_score_array,\n",
        "        # \"threshold\": threshold_array,\n",
        "        \"auc\": auc_array,\n",
        "    },\n",
        "    index=label_val.columns,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1_score</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>covid_stats</th>\n",
              "      <td>0.909535</td>\n",
              "      <td>0.962805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vaccination</th>\n",
              "      <td>0.972173</td>\n",
              "      <td>0.985576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>covid_politics</th>\n",
              "      <td>0.730946</td>\n",
              "      <td>0.783697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>humour</th>\n",
              "      <td>0.760933</td>\n",
              "      <td>0.787856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lockdown</th>\n",
              "      <td>0.972268</td>\n",
              "      <td>0.994387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>civic_views</th>\n",
              "      <td>0.740675</td>\n",
              "      <td>0.770747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>life_during_pandemic</th>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.610752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>covid_waves_and_variants</th>\n",
              "      <td>0.845827</td>\n",
              "      <td>0.914097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          f1_score       auc\n",
              "covid_stats               0.909535  0.962805\n",
              "vaccination               0.972173  0.985576\n",
              "covid_politics            0.730946  0.783697\n",
              "humour                    0.760933  0.787856\n",
              "lockdown                  0.972268  0.994387\n",
              "civic_views               0.740675  0.770747\n",
              "life_during_pandemic      0.602500  0.610752\n",
              "covid_waves_and_variants  0.845827  0.914097"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "f1_score    0.816857\n",
              "auc         0.851240\n",
              "dtype: float32"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "covid_stats                 415\n",
              "vaccination                 836\n",
              "covid_politics              507\n",
              "humour                      321\n",
              "lockdown                    311\n",
              "civic_views                 557\n",
              "life_during_pandemic        340\n",
              "covid_waves_and_variants    344\n",
              "dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos = label_val.sum()\n",
        "pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8632353528804668"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(results[\"auc\"] * pos).sum() / pos.sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "thresh_pred = model_label_predict >= threshold_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.825451647183847"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skm.f1_score(label_val, thresh_pred, average=\"micro\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8168571292917006"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skm.f1_score(label_val, thresh_pred, average=\"macro\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8305669357221502"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skm.f1_score(label_val, thresh_pred, average=\"weighted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Normalization MURIL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "3db1740dc4c63d05e0183029f245d99e342296d1ed403c3ef0b4079859e0c361"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
